import sys
import os
import re
import glob
import argparse
from pydub import AudioSegment
import scipy.io.wavfile as wavfile

from pyAudioAnalysis import audioBasicIO as aIO
from pyAudioAnalysis import audioSegmentation as aS

def mf_classify(filename):
    print('processing: ', filename)
    
    m_flags, f_flags, m_ratio, f_ratio, m_time, f_time = 0
    
    # TODO: Update model or method of classifying male/female speakers

    [flagsInd, classesAll, acc, CM] = aS.mtFileClassification(filename, "data/knnSpeakerFemaleMale", "knn", plot_results=False)
    print('flagsInd:   ', flagsInd)
    print('classesAll: ', classesAll)
    print('acc:        ', acc)
    print('CM:         ', CM)
    
    # TODO: One way to compute things
    
    # m_flags: Sum up the number of times 0 (male) appears in flagsInd 
    # f_flags: Sum up the number of times 1 (female) appears in flagsInd
    # m_ratio: Divide m_flags by total number of flags
    # f_ratio: Divide f_flags by total number of flags
    # m_time: Multiply m_flags by length of each segment (0.2 seconds ?)
    # f_time: Multiply f_flags by length of each segment
    
    return [m_ratio, f_ratio, m_time, f_time]



def removeSilence(filename, smoothing, weightThresh):
    print('Removing silence from ' + filename + '...')

    # Use pAA to remove silence and get the segments with audio.
    [Fs, x] = aIO.readAudioFile(filename)
    segments = aS.silenceRemoval(x, Fs, 0.020, 0.020, smoothWindow = smoothing, weight = weightThresh, plot = False)

    # FUTURE WORK: Possibility to do more processing on the speech segments. For example, if the
    # gap is very short, and the speaker switches from a man to a woman, it could
    # be evidence of an interruption.

    # Produce .wav files with speech activity.
    print('Creating .wav files from non-silent segments...')
    for i, s in enumerate(segments):
        strOut = "{0:s}_{1:.3f}-{2:.3f}.wav".format(filename[0:-4], s[0], s[1])
        wavfile.write(strOut, Fs, x[int(Fs * s[0]):int(Fs * s[1])])

    # Get basename of file without .wav extension.
    basename = re.findall('.*[^.wav]', filename)[0]
    pattern = basename + '_*.wav'
    infiles = glob.glob(pattern)

    # Insertion sort on filenames. Default sort() does not work here.
    print('Sorting filenames...')
    for i in range(1,len(infiles)):
        # Get starting timestamp of filename.
        currentFile = infiles[i]
        currentStartTime = re.findall('_[0-9]+\.[0-9]+', infiles[i])
        currentStartTime = float(currentStartTime[0][1:]) # remove leading underscore
        # Get starting timestamp of preceding filename.
        previousFile = infiles[i-1]
        previousStartTime = re.findall('_[0-9]+\.[0-9]+', infiles[i-1])
        previousStartTime = float(previousStartTime[0][1:])

        # print('previousStart: ' + str(previousStartTime) + ', currentstart: ' + str(currentStartTime))

        # Swap out of order elements until sorted.
        while i > 0 and previousStartTime > currentStartTime:
            infiles[i] = previousFile
            i = i - 1
            infiles[i] = currentFile
            # Update timestamps.
            previousFile = infiles[i-1]
            previousStartTime = re.findall('_[0-9]+\.[0-9]+', infiles[i-1])
            previousStartTime = float(previousStartTime[0][1:])
            currentFile = infiles[i]
            currentStartTime = re.findall('_[0-9]+\.[0-9]+', infiles[i])
            currentStartTime = float(currentStartTime[0][1:])

            # print('  i = ' + str(i) + ', previousStartTime = ' + str(previousStartTime) + ', currentStartTime = ' + str(currentStartTime))
            # print('    infiles[i-1]: ' + infiles[i-1] + ', infiles[i]: ' + infiles[i])

    # Use pydub to combine the list of files into a single .wav file.
    print('Combining segments with speech activity and removing files generated by pyAudioAnalysis silenceRemoval()')
    combined_sounds = AudioSegment.silent(duration=10) # create audio segment with 10 ms of silence
    for infile in infiles:
        # print(infile)
        combined_sounds = combined_sounds + AudioSegment.from_wav(infile)
        # Clean up and remove files generated by pAA silenceRemoval.
        os.remove(infile)

    outfile = basename + '-nosilence.wav'
    
    print('Writing output file: ' + outfile + '.')
    combined_sounds.export(outfile, format="wav")
    return outfile
